{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e04ea027-3a19-42cd-bae4-1780112d9d29",
   "metadata": {},
   "source": [
    "# 1. AWS Bedrock 기초 모델을 사용한 프로토타입\n",
    "CML 핸즈온 랩의 첫 번째 연습에 오신 것을 환영합니다. 이 노트북에서는 외부에서 호스팅되는 기초 모델을 호출하는 방법에 대해 알아봅니다. 이 연습에서는 AWS Bedrock 서비스와 거기에 호스팅된 ~Anthropic Claude~ Mistral 모델을 사용합니다.\n",
    "\n",
    "![image](../assets/jupypter-session-bedrock.png)\n",
    "\n",
    "### 1.1 Cloudera CML \n",
    "여기서 주목할 점은 AWS 서비스와 상호 작용하는 `boto3` SDK입니다. `get_bedrock_client` 함수는 AWS의 [github 저장소](https://github.com/aws-samples/amazon-bedrock-workshop/blob/109ed616fd14c9eb26eda9bef96eb78c490d5ef6/utils/bedrock.py#L13)에서 가져온 것입니다. 자신의 환경에서 이 코드를 실행하는 경우 AWS 키를 환경 변수로 설정하는 것이 좋습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58bc9967-bc2d-4ef5-a50d-9c8a27ded0d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from typing import Optional\n",
    "import boto3\n",
    "from botocore.config import Config\n",
    "\n",
    "if os.environ.get(\"AWS_ACCESS_KEY_ID\") == \"\":\n",
    "    os.environ[\"AWS_ACCESS_KEY_ID\"] = \"<YOUR-ACCESS-KEY-ID>\"   # Replace this if running in your own environment\n",
    "\n",
    "if os.environ.get(\"AWS_SECRET_ACCESS_KEY\") == \"\":\n",
    "    os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"<YOUR-SECRET-ACCESS-KEY>\"   # Replace this if running in your own environment\n",
    "\n",
    "if os.environ.get(\"AWS_FOUNDATION_MODEL_ID\") == \"\":\n",
    "    os.environ[\"AWS_FOUNDATION_MODEL_ID\"] = \"<FOUNDATION-MODEL-ID>\"   # Replace this if running in your own environment\n",
    "\n",
    "# TODO: for a lab, can reduce some of the checks in the below function\n",
    "def get_bedrock_client(\n",
    "    assumed_role: Optional[str] = None,\n",
    "    endpoint_url: Optional[str] = None,\n",
    "    region: Optional[str] = None,\n",
    "):\n",
    "    \"\"\"Create a boto3 client for Amazon Bedrock, with optional configuration overrides\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    assumed_role :\n",
    "        Optional ARN of an AWS IAM role to assume for calling the Bedrock service. If not\n",
    "        specified, the current active credentials will be used.\n",
    "    endpoint_url :\n",
    "        Optional override for the Bedrock service API Endpoint. If setting this, it should usually\n",
    "        include the protocol i.e. \"https://...\"\n",
    "    region :\n",
    "        Optional name of the AWS Region in which the service should be called (e.g. \"us-east-1\").\n",
    "        If not specified, AWS_REGION or AWS_DEFAULT_REGION environment variable will be used.\n",
    "    \"\"\"\n",
    "    if region is None:\n",
    "        target_region = os.environ.get(\"AWS_REGION\", os.environ.get(\"AWS_DEFAULT_REGION\"))\n",
    "    else:\n",
    "        target_region = region\n",
    "\n",
    "    print(f\"Create new client\\n  Using region: {target_region}\")\n",
    "    session_kwargs = {\"region_name\": target_region}\n",
    "    client_kwargs = {**session_kwargs}\n",
    "\n",
    "    profile_name = os.environ.get(\"AWS_PROFILE\")\n",
    "    if profile_name:\n",
    "        print(f\"  Using profile: {profile_name}\")\n",
    "        session_kwargs[\"profile_name\"] = profile_name\n",
    "\n",
    "    retry_config = Config(\n",
    "        region_name=target_region,\n",
    "        retries={\n",
    "            \"max_attempts\": 10,\n",
    "            \"mode\": \"standard\",\n",
    "        },\n",
    "    )\n",
    "    session = boto3.Session(**session_kwargs)\n",
    "\n",
    "    if assumed_role:\n",
    "        print(f\"  Using role: {assumed_role}\", end='')\n",
    "        sts = session.client(\"sts\")\n",
    "        response = sts.assume_role(\n",
    "            RoleArn=str(assumed_role),\n",
    "            RoleSessionName=\"langchain-llm-1\"\n",
    "        )\n",
    "        print(\" ... successful!\")\n",
    "        client_kwargs[\"aws_access_key_id\"] = response[\"Credentials\"][\"AccessKeyId\"]\n",
    "        client_kwargs[\"aws_secret_access_key\"] = response[\"Credentials\"][\"SecretAccessKey\"]\n",
    "        client_kwargs[\"aws_session_token\"] = response[\"Credentials\"][\"SessionToken\"]\n",
    "\n",
    "    if endpoint_url:\n",
    "        client_kwargs[\"endpoint_url\"] = endpoint_url\n",
    "\n",
    "    bedrock_client = session.client(\n",
    "        service_name=\"bedrock-runtime\",\n",
    "        config=retry_config,\n",
    "        **client_kwargs\n",
    "    )\n",
    "\n",
    "    print(\"boto3 Bedrock client successfully created!\")\n",
    "    print(bedrock_client._endpoint)\n",
    "    return bedrock_client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c45244-202e-487b-8134-a49f84c57b23",
   "metadata": {
    "tags": []
   },
   "source": [
    "그런 다음 클라이언트가 초기화되어 Bedrock 서비스를 사용할 수 있는 AWS 리전에 바인딩됩니다. [2023년 10월 현재](https://aws.amazon.com/about-aws/whats-new/2023/10/amazon-bedrock-asia-pacific-tokyo-aws-region/) 이러한 리전은 us-east-1, us-west-2 및 ap-northeast-1입니다. 기본값으로 `us-east-1`을 사용합니다. 이는 환경 변수로 덮어쓸 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8444b23e-f063-4923-b12e-54e453529ced",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create new client\n",
      "  Using region: us-west-2\n",
      "boto3 Bedrock client successfully created!\n",
      "bedrock-runtime(https://bedrock-runtime.us-west-2.amazonaws.com)\n"
     ]
    }
   ],
   "source": [
    "# Initializing the bedrock client using AWS credentials\n",
    "# If you are using a special Assumed role or custom endpoint url, see get_bedrock_client\n",
    "if os.environ.get(\"AWS_DEFAULT_REGION\") == \"\":\n",
    "    os.environ[\"AWS_DEFAULT_REGION\"] = \"us-west-2\"\n",
    "\n",
    "boto3_bedrock = get_bedrock_client(region=os.environ.get(\"AWS_DEFAULT_REGION\", None))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3118c5-e310-4748-96d8-61f2016deab8",
   "metadata": {},
   "source": [
    "### 1.3 원하는 지침(Instruction) 설정: Text Summarization\n",
    "이 노트북에 표시된 기반 모델(~Anthropic의 Claude~ Mistral)은 일반적인 instruction-following text 생성 모델입니다. 즉, 제공된 지침을 따르는 응답을 생성하기 위해 몇 가지 지침과 입력 텍스트를 제공할 수 있습니다. 예를 들어, 텍스트의 일부를 몇 개의 요점으로 요약하는 지침을 기초 모델에 제공합니다. 모델 지침은 일반적으로 규정된 패턴을 따르며 사용된 모델에 따라 달라집니다. 즉, 다른 모델에 지침을 제공하는 표준적인 방법은 없습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a09516a0-a82d-4101-a33d-0e101371bcce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "instruction_text = \"\"\"Human: Please provide a summary of the text inside <text></text> XML tags. Do not add any information that is not mentioned in this text. \n",
    "                             Provide no more than 3 bullet points in the summary, each being a complete sentece. \n",
    "                             Start your summary with simply saying \"Here's a brief summary of the provided text:\". \n",
    "                    <text>{{USER_TEXT}}</text>\n",
    "                    Assistant:\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31a9f24-193e-4afa-b203-f0d6e4a7bcd6",
   "metadata": {},
   "source": [
    "### 1.4 입력 텍스트 설정 및 완전한 프롬프트 생성 <a id='1.4'></a>\n",
    "아래는 요약하고자 하는 입력 텍스트입니다. 이 텍스트의 길이와 포함된 지침(Instruction)은 선택한 모델의 context window size에 맞아야 합니다. 클로드의 경우 약 9,000단어입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06fb50d0-4710-485c-8cc8-94503d868e9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_text = '''Machine learning has become one of the most critical capabilities for modern businesses to grow and stay competitive today. From automating internal processes to optimizing the design, creation, and marketing processes behind virtually every product consumed, ML models have permeated almost every aspect of our work and personal lives.\n",
    "ML development is iterative and complex, made even harder because most ML tools aren’t built for the entire machine learning lifecycle. Cloudera Machine Learning on Cloudera Data Platform accelerates time-to-value by enabling data scientists to collaborate in a single unified platform that is all inclusive for powering any AI use case. Purpose-built for agile experimentation and production ML workflows, Cloudera Machine Learning manages everything from data preparation to MLOps, to predictive reporting. Solve mission critical ML challenges along the entire lifecycle with greater speed and agility to discover opportunities which can mean the difference for your business.\n",
    "Each ML workspace enables teams of data scientists to develop, test, train, and ultimately deploy machine learning models for building predictive applications all on the data under management within the enterprise data cloud. ML workspaces support fully-containerized execution of Python, R, Scala, and Spark workloads through flexible and extensible engines.'''\n",
    "\n",
    "# Replace instruction placeholder to build a complete prompt\n",
    "full_prompt = instruction_text.replace(\"{{USER_TEXT}}\", input_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02a5494-4c00-4f8e-b5a3-22d7b1fd4a2b",
   "metadata": {},
   "source": [
    "### 1.5 LLM 모델에 대한 API 요청 생성\n",
    "Bedrock으로 보내 처리할 JSON 페이로드를 생성합니다. 이 API 요청에 필요한 매개변수와 형식은 모델에 따라 다릅니다. AWS Bedrock 설명서를 참조하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eeffaae5-c7f3-473d-99b8-e32d453cff42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mistral.mistral-7b-instruct-v0:2'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"AWS_FOUNDATION_MODEL_ID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d66c113-5b2b-4085-a386-783a09c8a4fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results successfully retreived\n"
     ]
    }
   ],
   "source": [
    "# Model expects a JSON object with a defined schema\n",
    "if 'claude' in os.environ[\"AWS_FOUNDATION_MODEL_ID\"].lower():\n",
    "    body = json.dumps({\"prompt\": full_prompt,\n",
    "             \"max_tokens_to_sample\":4096,\n",
    "             \"temperature\":0.6,\n",
    "             \"top_k\":250,\n",
    "             \"top_p\":1.0,\n",
    "             \"stop_sequences\":[]\n",
    "              })\n",
    "elif 'mistral' in os.environ[\"AWS_FOUNDATION_MODEL_ID\"].lower():\n",
    "    body = json.dumps({\"prompt\": full_prompt,\n",
    "             \"max_tokens\":200,\n",
    "             \"temperature\":0.5,\n",
    "             \"top_p\":0.9,\n",
    "             \"top_k\":50,\n",
    "              })\n",
    "\n",
    "\n",
    "\n",
    "# Provide a model ID and call the model with the JSON payload\n",
    "modelId = os.environ[\"AWS_FOUNDATION_MODEL_ID\"]\n",
    "response = boto3_bedrock.invoke_model(body=body, modelId=modelId, accept='application/json', contentType='application/json')\n",
    "response_body = json.loads(response.get('body').read())\n",
    "print(\"Model results successfully retreived\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c529eff-f072-404b-9be0-d3e06b283a9a",
   "metadata": {},
   "source": [
    "### 1.6 결과 검토"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc243a1d-7628-4dd2-8b56-722402bbdb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = response_body.get('outputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fcfb28b2-2874-40f4-adb8-9c09b9905a04",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'text': \" Here's a brief summary of the provided text:\\n1. Machine learning is a vital capability for businesses to grow and compete, influencing various aspects of work and personal life.\\n2. Cloudera Machine Learning on Cloudera Data Platform expedites the machine learning lifecycle, offering a unified platform for data scientists to collaborate.\\n3. This platform, purpose-built for ML workflows, manages data preparation to MLOps and predictive reporting, enabling faster solution of ML challenges.\", 'stop_reason': 'stop'}]\n"
     ]
    }
   ],
   "source": [
    "if 'claude' in os.environ[\"AWS_FOUNDATION_MODEL_ID\"].lower():\n",
    "    result = response_body.get('completion')\n",
    "elif 'mistral' in os.environ[\"AWS_FOUNDATION_MODEL_ID\"].lower():\n",
    "    result = response_body.get('outputs')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824ee10b-28e8-4bbd-93cc-0e7e40339c74",
   "metadata": {},
   "source": [
    "**(보너스)** [1.4단계](#1.4)로 돌아가서 모델이 요약할 다른 텍스트를 붙여넣습니다. 작업에서 어떻게 되는지 확인하세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f15aa4-80df-4b23-83f3-519a493c6b32",
   "metadata": {},
   "source": [
    "####  주요 사항\n",
    "\n",
    "* [Cloudera Machine Learning](https://docs.cloudera.com/machine-learning/cloud/product/topics/ml-product-overview.html#cdsw_overview)은 타사 기반 모델과 통합할 수 있는 유연한 환경을 제공합니다.\n",
    "* JupyterLabs는 지원되는 편집기이며, [사용자 정의 런타임](https://docs.cloudera.com/machine-learning/cloud/runtimes/topics/ml-creating-a-customized-runtimes-image.html)에 선택적으로 추가할 수 있는 다른 편집기도 있습니다(예: RStudio, VSCode)\n",
    "* 사용자는 가장 효율적인 개발 도구를 사용하여 LLM 솔루션을 빠르게 프로토타입화할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b86335-2991-46cc-9a03-f1f8c843108f",
   "metadata": {},
   "source": [
    "### 1.7 prototype_with_cml_model.ipynb 파일을 열어 CML 환경에서 배포된 LLM 모델을 호출해 보세요"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
